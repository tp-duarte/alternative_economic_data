{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_into_df(query, cursor):\n",
    "\t\"\"\"\n",
    "\n",
    "\tDescription: This function loads a SQL query into a pandas DataFrame.\n",
    "\n",
    "\tParameters:\n",
    "\n",
    "\ttable_name (str): A string containing the name of the table to be retrieved;\n",
    "\tcursor (database cursor): A cursor to make a connection with the database.\n",
    "\n",
    "\t\"\"\"\n",
    "\n",
    "\tcursor.execute(query)\n",
    "\tresult = cursor.fetchall()\n",
    "\tcolumn_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "\tdf = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'orange', 'banana', 'apple_dupplicated_1', 'apple_dupplicated_2', 'banana_dupplicated_1']\n"
     ]
    }
   ],
   "source": [
    "def add_suffix_to_duplicates(lst):\n",
    "    frequency = {}\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        if item in frequency:\n",
    "            frequency[item] += 1\n",
    "            item_with_suffix = item + \"_dupplicated_\" + str(frequency[item])\n",
    "            result.append(item_with_suffix)\n",
    "        else:\n",
    "            frequency[item] = 0\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "my_list = ['apple', 'orange', 'banana', 'apple', 'apple', 'banana']\n",
    "suffix = '_dup'\n",
    "result_list = add_suffix_to_duplicates(my_list,)\n",
    "print(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_into_h2o(query, cursor):\n",
    "    \"\"\"\n",
    "\n",
    "    Description: This function loads a SQL query into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    table_name (str): A string containing the name of the table to be retrieved;\n",
    "    cursor (database cursor): A cursor to make a connection with the database.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "    column_names = add_suffix_to_duplicates(column_names)\n",
    "\n",
    "    df = h2o.H2OFrame(result, column_names=column_names)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = r\"..\\alternative_economic_data\\data\\traditional_data\\staging_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.15+8-LTS-149, mixed mode)\n",
      "  Starting server from C:\\Users\\user-07\\miniconda3\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\user-07\\AppData\\Local\\Temp\\tmpzesstxxw\n",
      "  JVM stdout: C:\\Users\\user-07\\AppData\\Local\\Temp\\tmpzesstxxw\\h2o_user_07_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\user-07\\AppData\\Local\\Temp\\tmpzesstxxw\\h2o_user_07_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Sao_Paulo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>26 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_user_07_e5pty3</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.979 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.5 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O_cluster_uptime:         03 secs\n",
       "H2O_cluster_timezone:       America/Sao_Paulo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    26 days\n",
       "H2O_cluster_name:           H2O_from_python_user_07_e5pty3\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.979 Gb\n",
       "H2O_cluster_total_cores:    0\n",
       "H2O_cluster_allowed_cores:  0\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.5 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    db = psycopg2.connect(\n",
    "        host=\"aws-california.caclwjj7hnoo.us-east-2.rds.amazonaws.com\",\n",
    "        database=\"california\",\n",
    "        user=\"postgres\",\n",
    "        password=\"24567811\"\n",
    "    )\n",
    "    cursor = db.cursor()\n",
    "    print(\"Connected to the database!\")\n",
    "    \n",
    "    # Perform database operations here\n",
    "    \n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error connecting to the database:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "query_trad_data = \"SELECT trad.* \" \\\n",
    "                  \"FROM traditional_data AS trad\"\n",
    "                 \n",
    "query_alt_data = \"SELECT alt.*, trad.gdp \" \\\n",
    "                 \"FROM traditional_data AS trad \" \\\n",
    "                 \"JOIN alternative_data AS alt ON trad.date = alt.date\"\n",
    "\n",
    "query_all_data = \"SELECT trad.*, alt.* \" \\\n",
    "                 \"FROM traditional_data AS trad \" \\\n",
    "                 \"FULL OUTER JOIN alternative_data AS alt \" \\\n",
    "                 \"ON trad.date = alt.date\"\n",
    "\n",
    "traditional_data = query_into_h2o(query_trad_data, cursor)\n",
    "alternative_data = query_into_h2o(query_alt_data, cursor)\n",
    "all_data = query_into_h2o(query_all_data, cursor)\n",
    "all_data = all_data.drop(\"date_dupplicated_1\")\n",
    "\n",
    "db.close() # don't want to kill your finances in aws haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting data frames \n",
    "\n",
    "traditional_data = traditional_data.sort(by='date')\n",
    "alternative_data = alternative_data.sort(by='date')\n",
    "all_data = all_data.sort(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "### Predicting Expenditure and disposable Income \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expenditure:\n",
    "\n",
    "- Remove GDP and disp_inc\n",
    "\n",
    "Disp Income:\n",
    "\n",
    "- Remove GDP and expenditure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test data based on split time and columns to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(split_time, df, drop_from_features, target):\n",
    "    \"\"\"\n",
    "    Description: Splits data into training and test considerind a split date.\n",
    "    \n",
    "    Parameters:\n",
    "        split_time (str): A string with the split date in Y-m-d format;\n",
    "        df (h2o.H2OFrame): A h2o frame containing the data to be splitted;\n",
    "        drop_from_features (list): A list containing the features (and the target) to be dropped out of the training step;\n",
    "        target (str): The name of the target variable;\n",
    "    \n",
    "    Returns:\n",
    "        train (h2o.H2OFrame): The data for train;\n",
    "        test (h2o.H2OFrame): The data for test;\n",
    "        features (list): A list of features to predict the target;\n",
    "        target (str): A string of the target to predicted;\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    split_time = pd.to_datetime(split_time)\n",
    "    \n",
    "    train = df[df[\"date\"] <  split_time]\n",
    "    test = df[df[\"date\"] >=  split_time]\n",
    "    \n",
    "    features = train.columns\n",
    "    features = [feature_col for feature_col in features if feature_col not in drop_from_features]\n",
    "    \n",
    "    return train, test, features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "16:55:49.612: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "\n",
      "16:55:50.459: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 56.0.\n",
      "\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "## Expenditure data\n",
    "\n",
    "split_date = \"2019-01-01\"\n",
    "drop_from_expend = [\"gdp\", \"disposable_income\", \"expenditure\"]\n",
    "\n",
    "train_expend, test_expend, features_expend, expend = data_split(split_date, traditional_data, drop_from_expend, \"expenditure\")\n",
    "\n",
    "# Initializing and training model \n",
    "\n",
    "expendt_model = H2OAutoML(max_runtime_secs=10)\n",
    "expendt_model.train(x=features_expend, y=expend, training_frame=train_expend)\n",
    "\n",
    "# Predictions  \n",
    "\n",
    "predictions_expend = expendt_model.predict(test_expend[features_expend])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "16:56:01.979: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "\n",
      "16:56:02.262: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 56.0.\n",
      "\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "## Disposable Income \n",
    "\n",
    "drop_from_disp = [\"gdp\", \"disposable_income\", \"expenditure\"]\n",
    "\n",
    "train_disp, test_disp, features_disp, disp = data_split(split_date, traditional_data, drop_from_disp, \"disposable_income\")\n",
    "\n",
    "# Initializing and training model \n",
    "\n",
    "disp_model = H2OAutoML(max_runtime_secs=10)\n",
    "disp_model.train(x=features_disp, y=disp, training_frame=train_disp)\n",
    "\n",
    "# Predictions  \n",
    "\n",
    "predictions_disp = disp_model.predict(test_disp[features_disp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "16:56:13.906: AutoML: XGBoost is not available; skipping it.\n",
      "16:56:14.125: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 56.0.\n",
      "\n",
      "██████████████████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "## Traditional Data\n",
    "\n",
    "\n",
    "drop_from_trad = [\"gdp\"]\n",
    "\n",
    "train_trad, test_trad, features_trad, gdp = data_split(split_date, traditional_data, drop_from_trad, \"gdp\")\n",
    "\n",
    "# replacing expenditure and tradosable income data in the test \n",
    "\n",
    "test_trad[\"expenditure\"] = predictions_expend\n",
    "test_trad[\"disposable_income\"] = predictions_disp\n",
    "\n",
    "# Initializing and training model \n",
    "\n",
    "trad_model = H2OAutoML(max_runtime_secs=10)\n",
    "trad_model.train(x=features_trad, y=gdp, training_frame=train_trad)\n",
    "\n",
    "# Predictions  \n",
    "\n",
    "predictions_trad = trad_model.predict(test_trad[features_trad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "16:56:39.977: AutoML: XGBoost is not available; skipping it.\n",
      "16:56:39.977: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:56:40.77: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:56:40.77: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 56.0.\n",
      "16:56:40.77: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "\n",
      "16:56:40.499: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "█\n",
      "16:56:40.970: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "██████\n",
      "16:56:42.116: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "███\n",
      "16:56:43.293: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "██████\n",
      "16:56:43.403: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:56:43.528: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "██████\n",
      "16:56:44.532: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:56:45.65: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:56:45.160: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "████████\n",
      "16:56:45.269: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "████████████████████████████\n",
      "16:56:49.428: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "█████| (done) 100%\n",
      "\n",
      "16:56:49.538: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "## Alternative Data\n",
    "\n",
    "\n",
    "drop_from_alt = [\"gdp\"]\n",
    "\n",
    "train_alt, test_alt, features_alt, gdp = data_split(split_date, alternative_data, drop_from_alt, \"gdp\")\n",
    "\n",
    "\n",
    "# Initializing and training model \n",
    "\n",
    "alt_model = H2OAutoML(max_runtime_secs=10)\n",
    "alt_model.train(x=features_alt, y=gdp, training_frame=train_alt)\n",
    "\n",
    "# Predictions  \n",
    "\n",
    "predictions_alt = alt_model.predict(test_alt[features_alt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">    predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">2.69554e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.90775e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.7533e+06 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.84332e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.64756e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.33227e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.37963e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.43005e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.43017e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">2.47272e+06</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[16 rows x 1 column]</pre>"
      ],
      "text/plain": [
       "    predict\n",
       "-----------\n",
       "2.69554e+06\n",
       "2.90775e+06\n",
       "2.7533e+06\n",
       "2.84332e+06\n",
       "2.64756e+06\n",
       "2.33227e+06\n",
       "2.37963e+06\n",
       "2.43005e+06\n",
       "2.43017e+06\n",
       "2.47272e+06\n",
       "[16 rows x 1 column]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "16:58:28.610: AutoML: XGBoost is not available; skipping it.\n",
      "16:58:28.610: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:58:28.706: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:58:28.706: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 56.0.\n",
      "16:58:28.706: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "\n",
      "16:58:29.285: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "█\n",
      "16:58:29.912: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "██████\n",
      "16:58:30.854: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "███████\n",
      "16:58:32.266: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:58:32.391: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:58:32.517: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "█████████████\n",
      "16:58:33.646: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:58:34.384: _train param, Dropping bad and constant columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:58:34.447: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "█████████\n",
      "16:58:34.572: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "█████████████████████████\n",
      "16:58:38.134: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "16:58:38.259: _train param, Dropping unused columns: [mob_workplaces, mob_leisure, mob_groc_pharm, mob_transit, mob_parks, mob_residential]\n",
      "\n",
      "██| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "## All Data\n",
    "\n",
    "drop_from_all = [\"gdp\"]\n",
    "\n",
    "train_all, test_all, features_all, gdp = data_split(split_date, all_data, drop_from_all, \"gdp\")\n",
    "\n",
    "# replacing expenditure and disposable income data in the test \n",
    "\n",
    "test_all[\"expenditure\"] = predictions_expend\n",
    "test_all[\"disposable_income\"] = predictions_disp\n",
    "\n",
    "# Initializing and training model \n",
    "\n",
    "all_model = H2OAutoML(max_runtime_secs=10)\n",
    "all_model.train(x=features_all, y=gdp, training_frame=train_all)\n",
    "\n",
    "# Predictions  \n",
    "\n",
    "predictions_all = all_model.predict(test_all[features_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting models metrics and results\n",
    "\n",
    "def calculate_metrics(actual_frame, predicted_frame):\n",
    "    \"\"\"\n",
    "    Calculate RMSE, MAE, and R-squared metrics.\n",
    "\n",
    "    Parameters:\n",
    "        actual_frame (H2OFrame): The actual target values;\n",
    "        predicted_frame (H2OFrame): The predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing the calculated metrics.\n",
    "        \n",
    "    \"\"\"\n",
    "    actual_values = actual_frame.as_data_frame().values.flatten()\n",
    "    predicted_values = predicted_frame.as_data_frame().values.flatten()\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(actual_values, predicted_values))\n",
    "    mae = mean_absolute_error(actual_values, predicted_values)\n",
    "    r2 = r2_score(actual_values, predicted_values)\n",
    "\n",
    "    return {\"RMSE\": rmse, \"MAE\": mae, \"R-squared\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(models, actual_values, predicted_values):\n",
    "    \"\"\"\n",
    "    Display the performance metrics for each model in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    models (list): A list of model names.\n",
    "    actual_values (H2OFrame): H2OFrame with the actual target values.\n",
    "    predicted_values (list): A list of H2OFrames with the predicted target values for each model.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the performance metrics for each model.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    actual_values = [actual_values]\n",
    "    actual_values = len(models) * actual_values\n",
    "    \n",
    "    for model_name, actual, predicted in zip(models, actual_values, predicted_values):\n",
    "        \n",
    "        metrics = calculate_metrics(actual, predicted)\n",
    "        results[model_name] = metrics\n",
    "\n",
    "    df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"trad_model\", \"alt_model\", \"all_model\"]\n",
    "predictions = [predictions_trad, predictions_alt, predictions_all]\n",
    "actual_gdp = test_all[\"gdp\"]\n",
    "\n",
    "models_metrics = display_metrics(models, actual_gdp, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flattened_dict = {\n",
    "    \"real_gdp\": test_all[\"gdp\"].as_data_frame(),\n",
    "    \"trad_predictions\": predictions_trad.as_data_frame(),\n",
    "    \"alt_predictions\": predictions_alt.as_data_frame(),\n",
    "    \"all_predictions\": predictions_all.as_data_frame()\n",
    "}\n",
    "\n",
    "prediction_results = pd.concat(flattened_dict.values(), axis=1, keys=flattened_dict.keys())\n",
    "prediction_results.columns = df.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trad_model</th>\n",
       "      <td>456992.942918</td>\n",
       "      <td>411460.930665</td>\n",
       "      <td>-2.126441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alt_model</th>\n",
       "      <td>810908.480685</td>\n",
       "      <td>725938.103490</td>\n",
       "      <td>-8.844075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_model</th>\n",
       "      <td>535236.272115</td>\n",
       "      <td>471733.738303</td>\n",
       "      <td>-3.288667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RMSE            MAE  R-squared\n",
       "trad_model  456992.942918  411460.930665  -2.126441\n",
       "alt_model   810908.480685  725938.103490  -8.844075\n",
       "all_model   535236.272115  471733.738303  -3.288667"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_gdp</th>\n",
       "      <th>trad_predictions</th>\n",
       "      <th>alt_predictions</th>\n",
       "      <th>all_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2970816.1</td>\n",
       "      <td>2.860293e+06</td>\n",
       "      <td>2.695538e+06</td>\n",
       "      <td>2.850353e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3028633.1</td>\n",
       "      <td>2.875415e+06</td>\n",
       "      <td>2.907747e+06</td>\n",
       "      <td>2.921068e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3062616.7</td>\n",
       "      <td>2.877514e+06</td>\n",
       "      <td>2.753299e+06</td>\n",
       "      <td>2.866119e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3108710.4</td>\n",
       "      <td>2.876494e+06</td>\n",
       "      <td>2.843319e+06</td>\n",
       "      <td>2.906935e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3074465.6</td>\n",
       "      <td>2.863346e+06</td>\n",
       "      <td>2.647556e+06</td>\n",
       "      <td>2.880532e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2812435.1</td>\n",
       "      <td>2.523797e+06</td>\n",
       "      <td>2.332269e+06</td>\n",
       "      <td>2.559647e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3060840.2</td>\n",
       "      <td>2.751774e+06</td>\n",
       "      <td>2.379633e+06</td>\n",
       "      <td>2.651723e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3132952.5</td>\n",
       "      <td>2.770401e+06</td>\n",
       "      <td>2.430049e+06</td>\n",
       "      <td>2.673481e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3225265.8</td>\n",
       "      <td>2.742547e+06</td>\n",
       "      <td>2.430171e+06</td>\n",
       "      <td>2.654312e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3331416.0</td>\n",
       "      <td>2.832152e+06</td>\n",
       "      <td>2.472724e+06</td>\n",
       "      <td>2.701793e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3416146.0</td>\n",
       "      <td>2.878226e+06</td>\n",
       "      <td>2.428160e+06</td>\n",
       "      <td>2.786955e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3520134.9</td>\n",
       "      <td>2.943221e+06</td>\n",
       "      <td>2.406061e+06</td>\n",
       "      <td>2.822670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3497723.7</td>\n",
       "      <td>2.939500e+06</td>\n",
       "      <td>2.448009e+06</td>\n",
       "      <td>2.828228e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3558511.9</td>\n",
       "      <td>2.939596e+06</td>\n",
       "      <td>2.443435e+06</td>\n",
       "      <td>2.828084e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3634821.3</td>\n",
       "      <td>2.939596e+06</td>\n",
       "      <td>2.460863e+06</td>\n",
       "      <td>2.828977e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3701354.1</td>\n",
       "      <td>2.939596e+06</td>\n",
       "      <td>2.443002e+06</td>\n",
       "      <td>2.828228e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     real_gdp  trad_predictions  alt_predictions  all_predictions\n",
       "0   2970816.1      2.860293e+06     2.695538e+06     2.850353e+06\n",
       "1   3028633.1      2.875415e+06     2.907747e+06     2.921068e+06\n",
       "2   3062616.7      2.877514e+06     2.753299e+06     2.866119e+06\n",
       "3   3108710.4      2.876494e+06     2.843319e+06     2.906935e+06\n",
       "4   3074465.6      2.863346e+06     2.647556e+06     2.880532e+06\n",
       "5   2812435.1      2.523797e+06     2.332269e+06     2.559647e+06\n",
       "6   3060840.2      2.751774e+06     2.379633e+06     2.651723e+06\n",
       "7   3132952.5      2.770401e+06     2.430049e+06     2.673481e+06\n",
       "8   3225265.8      2.742547e+06     2.430171e+06     2.654312e+06\n",
       "9   3331416.0      2.832152e+06     2.472724e+06     2.701793e+06\n",
       "10  3416146.0      2.878226e+06     2.428160e+06     2.786955e+06\n",
       "11  3520134.9      2.943221e+06     2.406061e+06     2.822670e+06\n",
       "12  3497723.7      2.939500e+06     2.448009e+06     2.828228e+06\n",
       "13  3558511.9      2.939596e+06     2.443435e+06     2.828084e+06\n",
       "14  3634821.3      2.939596e+06     2.460863e+06     2.828977e+06\n",
       "15  3701354.1      2.939596e+06     2.443002e+06     2.828228e+06"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_results.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
